---
title: "Prediction of Diabetes"
author: "Sridhar"
date: "August 8, 2018"
output: 
  prettydoc::html_pretty:
    theme: cayman
    highlight: github
---
## Introduction

The diabetes is threatening a lot of people nowadays, without having a perfect cure for it.There are actually two types of diabetes,namely Type 1 and Type 2.The type 2 diabetes is commonly called as diabetes mellitus.It can be defined as a chronic condition that affects the way the body processes blood sugar (glucose).We consider the mellitus here.After deep researches we found that, that some parameters are directly responsible to for the mellitus to occur.By using the data of the people with and without diabetes,a dataset has been build.We use that dataset to classify the people who are in the risk of getting diabetes.

## Loading the required libraries
```{r message=FALSE,warning=FALSE}
library(ggplot2)
library(ggvis)
library(corrplot)
library(caTools)
library(ROCR)
```

## Data Loading
The observations of the people are stored in a CSV format, named diabetes.csv.The data is loaded in the environment.Let's check how the data is structured.
```{r}
data = read.csv("C:/Users/crsri/Documents/Diabetes_Prediction/Data/diabetes.csv")
head(data)
summary(data)
str(data)
```

## Correlations

The proportionalities of the attributes of the data can be identified by the  correlation coefficient,either numerically or visually.They helps to know which attributes are highy dependent on the prediction variable:Outcome.
```{r}
correlations <- cor(data)
correlations
corrplot(correlations, method="color")
```

## Visualization
Visualizations are used to grasp the structure of data and its relations,like how they vary and their 
relationships with the otehr data.They are said to be EDA.

A matrix of scatterplots is produce for this dataset.
```{r}
pairs(data, col=data$Outcome)
```

### Glucose and Insulin

The glucose and the insulin are the major factors of the diabetes...which in turn have direct proportionality in the future during the diabetes.They are the major cause of the occurence.They are strong correlated on each other.
```{r}
data %>% ggvis(~Glucose,~Insulin,fill =~Outcome) %>% layer_points()
```

### BMI ad DiabetesPedigreeFunction

The BMI and DiabetesPedigreeFunction is plotted here.
```{r}
data %>% ggvis(~BMI,~DiabetesPedigreeFunction,fill =~Outcome) %>% layer_points()
```

### Age and Pregnancies

The males have 0 for the pregnancy attribute, which is why we find a lot of values plottinh zero in this grpah.
```{r}
data %>% ggvis(~Age,~Pregnancies,fill =~Outcome) %>% layer_points()
```

## Preparing the data

The dataset is divided as two parts, training data and testing data, with a Splitratio of 0.75. It means that 2/3rds of the data is labelled by training set and the rest 1/3rd of data is the testing set.The division of the dataset is by means of a random order generated by the seed.
```{r}
set.seed(88)
split <- sample.split(data$Outcome, SplitRatio = 0.75)
data_train <- subset(data, split == TRUE)
data_test <- subset(data, split == FALSE)
```



## Logistic regression

The Logistic regression helps to classify the concern person will get diabetes or not.Since we are using the logistic regression we have to mention that, family = binomial.We are using all the attributes we have in the dataset.Let us take a look at the summary.
```{r}
model <- glm (Outcome ~ .-Pregnancies + Glucose + BloodPressure + SkinThickness + Insulin + BMI + DiabetesPedigreeFunction + Age, data = data_train, family = binomial)
summary(model)
```

## Prediction

The trained model is used to predict the data for the testing data and for the training data(For checking accuracy purposes and for ROC curve)
```{r}
predict_train <- predict(model, type = 'response')
predict_test <- predict(model, newdata = data_test, type = 'response')

```

## ROC Curve

```{r}

ROCRpred <- prediction(predict_train, data_train$Outcome)
ROCRperf <- performance(ROCRpred, 'tpr','fpr')
plot(ROCRperf, colorize = TRUE, text.adj = c(-0.2,1.7))

```

## Comparison

By comparing the real values with the real data, we can see the how our machine learning algorithm performs.
```{r}
predict_test_c = predict_test
i = 1
while(i <= length(predict_test))
{
  if(predict_test[i] < 0.5)
    predict_test_c[i] = 0
  else
    predict_test_c[i] = 1
  i = i + 1;
}
compare <- data.frame(data_test$Outcome,predict_test_c)
colnames(compare) <- c("Observed Values","Predicted values")
ggplot(data = compare,aes(x = "Observed Values", y = "Predicted values")) + geom_abline() +
  xlab("Observed Values") + ylab("Predicted values") + theme_classic()
compare
```

## Conclusion

The results can be improved by applyting the feature scaling and data cleaning.From this project we predict the type 2 diabetes, commonly called as diabetes mellitus.As a result it can help to improve their health conditions.

### Things to do in future

Data cleaning and Feature Scaling have to be done with the data.Then running the prepared data with the logistic regression to get the improved results.
